{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import os\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "os.chdir(os.path.dirname(os.path.realpath(\"__file__\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "# coco format dataset을 등록합니다. \n",
    "# 입력 파라메터 설명: (\"데이터셋 이름\", \"메타데이터\", \"json 경로\", \"이미지들의 경로\")\n",
    "register_coco_instances(\"Duck-Farm-train\", {}, \"../datasets/Duck-Farm/annotations/labels_train.json\", \"../datasets/Duck-Farm/train2017\")\n",
    "register_coco_instances(\"Duck-Farm-val\", {}, \"../datasets/Duck-Farm/annotations/labels_val.json\", \"../datasets/Duck-Farm/val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/koowater/.local/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    }
   ],
   "source": [
    "# config 객체를 선언하고 불러옵니다.\n",
    "cfg = get_cfg()\n",
    "# cfg.merge_from_list(['MODEL.DEVICE','cpu'])  # For cpu mode.\n",
    "# Detectron2에서 사전 정의한 retinanet config 파일을 불러옵니다.\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\"))\n",
    "# 학습 데이터셋, 테스트 데이터셋\n",
    "cfg.DATASETS.TRAIN = (\"Duck-Farm-train\",)\n",
    "cfg.DATASETS.TEST = (\"Duck-Farm-val\",)\n",
    "# 데이터를 불러오는 loader의 수를 정합니다. 일반적으로 'cpu 코어의 수 / 2'만큼 설정합니다. 큰 영향은 끼치지 않는 것 같습니다.\n",
    "cfg.DATALOADER.NUM_WORKERS =  4\n",
    "# pretrained checkpoint를 불러옵니다.\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_1x\")\n",
    "# batch size입니다.\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "# 학습 수행 시의 iteration 횟수입니다.\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "# checkpoint를 저장하는 iteration 간격을 설정합니다.\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 50\n",
    "# base learning rate를 설정합니다.\n",
    "cfg.SOLVER.BASE_LR = 0.001  \n",
    "# WarmupMultiStepLR의 step을 설정합니다. 적용하지 않기를 원하기 때문에 빈 list를 넣었습니다.\n",
    "cfg.SOLVER.STEPS = []  # do not decay learning rate\n",
    "# retinanet이 추론할 class의 수를 설정합니다.\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 21:59:33 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/05 21:59:33 d2.data.datasets.coco]: \u001b[0mLoaded 886 images in COCO format from ../datasets/Duck-Farm/annotations/labels_train.json\n",
      "\u001b[32m[04/05 21:59:33 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 886 images left.\n",
      "\u001b[32m[04/05 21:59:33 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    duck    | 1693         |  slapped   | 6            |    dead    | 58           |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 1757         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/05 21:59:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/05 21:59:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/05 21:59:33 d2.data.common]: \u001b[0mSerializing 886 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 21:59:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (27, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (27,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mhead.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 21:59:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koowater/.local/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 21:59:54 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 19  total_loss: 1.742  loss_cls: 1.37  loss_box_reg: 0.3777  time: 0.9427  data_time: 0.0139  lr: 1.9981e-05  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:00:09 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 39  total_loss: 1.339  loss_cls: 1.068  loss_box_reg: 0.271  time: 0.8413  data_time: 0.0041  lr: 3.9961e-05  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:00:25 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 59  total_loss: 1.109  loss_cls: 0.8988  loss_box_reg: 0.2281  time: 0.8110  data_time: 0.0041  lr: 5.9941e-05  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:00:40 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 79  total_loss: 0.8292  loss_cls: 0.5917  loss_box_reg: 0.2223  time: 0.8006  data_time: 0.0043  lr: 7.9921e-05  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:00:56 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 99  total_loss: 0.6639  loss_cls: 0.4603  loss_box_reg: 0.2306  time: 0.7966  data_time: 0.0042  lr: 9.9901e-05  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:01:11 d2.utils.events]: \u001b[0m eta: 0:37:12  iter: 119  total_loss: 0.6654  loss_cls: 0.4178  loss_box_reg: 0.2149  time: 0.7921  data_time: 0.0041  lr: 0.00011988  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:01:27 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 139  total_loss: 0.5847  loss_cls: 0.3723  loss_box_reg: 0.2071  time: 0.7912  data_time: 0.0042  lr: 0.00013986  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:01:43 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 159  total_loss: 0.5935  loss_cls: 0.3662  loss_box_reg: 0.2166  time: 0.7913  data_time: 0.0041  lr: 0.00015984  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:01:59 d2.utils.events]: \u001b[0m eta: 0:36:27  iter: 179  total_loss: 0.5838  loss_cls: 0.3753  loss_box_reg: 0.2117  time: 0.7903  data_time: 0.0041  lr: 0.00017982  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:02:15 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 199  total_loss: 0.5205  loss_cls: 0.3149  loss_box_reg: 0.2008  time: 0.7906  data_time: 0.0041  lr: 0.0001998  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:02:30 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 219  total_loss: 0.517  loss_cls: 0.3295  loss_box_reg: 0.2005  time: 0.7890  data_time: 0.0039  lr: 0.00021978  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:02:46 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 239  total_loss: 0.49  loss_cls: 0.3038  loss_box_reg: 0.1815  time: 0.7872  data_time: 0.0043  lr: 0.00023976  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:03:01 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 259  total_loss: 0.4938  loss_cls: 0.3035  loss_box_reg: 0.1819  time: 0.7861  data_time: 0.0043  lr: 0.00025974  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:03:17 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 279  total_loss: 0.5325  loss_cls: 0.3339  loss_box_reg: 0.2012  time: 0.7844  data_time: 0.0043  lr: 0.00027972  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:03:32 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 299  total_loss: 0.4831  loss_cls: 0.2967  loss_box_reg: 0.1735  time: 0.7832  data_time: 0.0043  lr: 0.0002997  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:03:48 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 319  total_loss: 0.4829  loss_cls: 0.2919  loss_box_reg: 0.1871  time: 0.7821  data_time: 0.0042  lr: 0.00031968  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:04:03 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 339  total_loss: 0.4807  loss_cls: 0.2833  loss_box_reg: 0.1807  time: 0.7814  data_time: 0.0044  lr: 0.00033966  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:04:19 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 359  total_loss: 0.4504  loss_cls: 0.2791  loss_box_reg: 0.1625  time: 0.7816  data_time: 0.0044  lr: 0.00035964  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:04:34 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 379  total_loss: 0.464  loss_cls: 0.2836  loss_box_reg: 0.179  time: 0.7810  data_time: 0.0044  lr: 0.00037962  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:04:50 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 399  total_loss: 0.4585  loss_cls: 0.2826  loss_box_reg: 0.1727  time: 0.7811  data_time: 0.0045  lr: 0.0003996  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:05:06 d2.utils.events]: \u001b[0m eta: 0:33:25  iter: 419  total_loss: 0.4403  loss_cls: 0.2706  loss_box_reg: 0.1553  time: 0.7801  data_time: 0.0045  lr: 0.00041958  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:05:21 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 439  total_loss: 0.4671  loss_cls: 0.2837  loss_box_reg: 0.1709  time: 0.7785  data_time: 0.0045  lr: 0.00043956  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:05:36 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 459  total_loss: 0.4727  loss_cls: 0.2985  loss_box_reg: 0.1721  time: 0.7776  data_time: 0.0044  lr: 0.00045954  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:05:51 d2.utils.events]: \u001b[0m eta: 0:32:37  iter: 479  total_loss: 0.411  loss_cls: 0.2627  loss_box_reg: 0.1506  time: 0.7770  data_time: 0.0052  lr: 0.00047952  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:06:07 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 499  total_loss: 0.4464  loss_cls: 0.2859  loss_box_reg: 0.1538  time: 0.7767  data_time: 0.0045  lr: 0.0004995  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:06:23 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 519  total_loss: 0.4272  loss_cls: 0.2695  loss_box_reg: 0.1457  time: 0.7768  data_time: 0.0043  lr: 0.00051948  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:06:38 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 539  total_loss: 0.4249  loss_cls: 0.2668  loss_box_reg: 0.1568  time: 0.7769  data_time: 0.0042  lr: 0.00053946  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:06:54 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 559  total_loss: 0.4317  loss_cls: 0.2594  loss_box_reg: 0.1679  time: 0.7765  data_time: 0.0044  lr: 0.00055944  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:07:09 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 579  total_loss: 0.4255  loss_cls: 0.2701  loss_box_reg: 0.1573  time: 0.7756  data_time: 0.0044  lr: 0.00057942  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:07:24 d2.utils.events]: \u001b[0m eta: 0:31:06  iter: 599  total_loss: 0.4275  loss_cls: 0.2586  loss_box_reg: 0.1591  time: 0.7751  data_time: 0.0043  lr: 0.0005994  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:07:40 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 619  total_loss: 0.4194  loss_cls: 0.2693  loss_box_reg: 0.154  time: 0.7748  data_time: 0.0044  lr: 0.00061938  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:07:55 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 639  total_loss: 0.4286  loss_cls: 0.2572  loss_box_reg: 0.1714  time: 0.7750  data_time: 0.0043  lr: 0.00063936  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:08:11 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 659  total_loss: 0.4138  loss_cls: 0.2465  loss_box_reg: 0.1667  time: 0.7745  data_time: 0.0045  lr: 0.00065934  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:08:26 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 679  total_loss: 0.4212  loss_cls: 0.2566  loss_box_reg: 0.1583  time: 0.7738  data_time: 0.0043  lr: 0.00067932  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:08:41 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 699  total_loss: 0.3945  loss_cls: 0.2447  loss_box_reg: 0.1437  time: 0.7738  data_time: 0.0043  lr: 0.0006993  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:08:57 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 719  total_loss: 0.3986  loss_cls: 0.2597  loss_box_reg: 0.163  time: 0.7738  data_time: 0.0043  lr: 0.00071928  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:09:12 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 739  total_loss: 0.4074  loss_cls: 0.2549  loss_box_reg: 0.1491  time: 0.7732  data_time: 0.0044  lr: 0.00073926  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:09:28 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 759  total_loss: 0.4242  loss_cls: 0.2601  loss_box_reg: 0.1632  time: 0.7734  data_time: 0.0044  lr: 0.00075924  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:09:43 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 779  total_loss: 0.3999  loss_cls: 0.2556  loss_box_reg: 0.1553  time: 0.7731  data_time: 0.0044  lr: 0.00077922  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:09:59 d2.utils.events]: \u001b[0m eta: 0:28:30  iter: 799  total_loss: 0.4018  loss_cls: 0.2547  loss_box_reg: 0.1442  time: 0.7729  data_time: 0.0042  lr: 0.0007992  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:10:14 d2.utils.events]: \u001b[0m eta: 0:28:15  iter: 819  total_loss: 0.4156  loss_cls: 0.2604  loss_box_reg: 0.1649  time: 0.7727  data_time: 0.0043  lr: 0.00081918  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:10:30 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 839  total_loss: 0.3969  loss_cls: 0.2543  loss_box_reg: 0.145  time: 0.7728  data_time: 0.0044  lr: 0.00083916  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:10:45 d2.utils.events]: \u001b[0m eta: 0:27:44  iter: 859  total_loss: 0.369  loss_cls: 0.2345  loss_box_reg: 0.143  time: 0.7726  data_time: 0.0044  lr: 0.00085914  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:11:01 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 879  total_loss: 0.4064  loss_cls: 0.252  loss_box_reg: 0.1583  time: 0.7727  data_time: 0.0043  lr: 0.00087912  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:11:17 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 899  total_loss: 0.401  loss_cls: 0.2406  loss_box_reg: 0.1438  time: 0.7728  data_time: 0.0044  lr: 0.0008991  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:11:32 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 919  total_loss: 0.3668  loss_cls: 0.2299  loss_box_reg: 0.1426  time: 0.7729  data_time: 0.0044  lr: 0.00091908  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:11:47 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 939  total_loss: 0.3635  loss_cls: 0.2288  loss_box_reg: 0.1454  time: 0.7725  data_time: 0.0044  lr: 0.00093906  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:12:03 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 959  total_loss: 0.4201  loss_cls: 0.2521  loss_box_reg: 0.1588  time: 0.7722  data_time: 0.0045  lr: 0.00095904  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:12:18 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 979  total_loss: 0.374  loss_cls: 0.234  loss_box_reg: 0.1325  time: 0.7723  data_time: 0.0045  lr: 0.00097902  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:12:34 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 999  total_loss: 0.3961  loss_cls: 0.24  loss_box_reg: 0.1636  time: 0.7722  data_time: 0.0043  lr: 0.000999  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:12:49 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 1019  total_loss: 0.3861  loss_cls: 0.2561  loss_box_reg: 0.1347  time: 0.7720  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:13:05 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 1039  total_loss: 0.4023  loss_cls: 0.253  loss_box_reg: 0.1436  time: 0.7721  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:13:20 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 1059  total_loss: 0.3864  loss_cls: 0.2426  loss_box_reg: 0.1391  time: 0.7720  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:13:36 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 1079  total_loss: 0.3879  loss_cls: 0.2528  loss_box_reg: 0.1403  time: 0.7721  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:13:51 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 1099  total_loss: 0.3574  loss_cls: 0.2148  loss_box_reg: 0.144  time: 0.7719  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:14:07 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 1119  total_loss: 0.3867  loss_cls: 0.2398  loss_box_reg: 0.1473  time: 0.7720  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:14:22 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 1139  total_loss: 0.3763  loss_cls: 0.2299  loss_box_reg: 0.1415  time: 0.7719  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:14:38 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 1159  total_loss: 0.3559  loss_cls: 0.2206  loss_box_reg: 0.1235  time: 0.7717  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:14:53 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 1179  total_loss: 0.3341  loss_cls: 0.2062  loss_box_reg: 0.1346  time: 0.7717  data_time: 0.0042  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:15:08 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 1199  total_loss: 0.3794  loss_cls: 0.2368  loss_box_reg: 0.1481  time: 0.7715  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:15:24 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 1219  total_loss: 0.3597  loss_cls: 0.2212  loss_box_reg: 0.1304  time: 0.7716  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:15:39 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 1239  total_loss: 0.3434  loss_cls: 0.2182  loss_box_reg: 0.1317  time: 0.7715  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:15:55 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 1259  total_loss: 0.3936  loss_cls: 0.2446  loss_box_reg: 0.1339  time: 0.7712  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:16:10 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 1279  total_loss: 0.3855  loss_cls: 0.2404  loss_box_reg: 0.1437  time: 0.7712  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:16:26 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 1299  total_loss: 0.3981  loss_cls: 0.2375  loss_box_reg: 0.1532  time: 0.7710  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:16:41 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 1319  total_loss: 0.3695  loss_cls: 0.2344  loss_box_reg: 0.1366  time: 0.7709  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:16:56 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 1339  total_loss: 0.3747  loss_cls: 0.2338  loss_box_reg: 0.1353  time: 0.7709  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:17:12 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 1359  total_loss: 0.3736  loss_cls: 0.2215  loss_box_reg: 0.1513  time: 0.7709  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:17:27 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 1379  total_loss: 0.3552  loss_cls: 0.2088  loss_box_reg: 0.1321  time: 0.7709  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:17:43 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 1399  total_loss: 0.349  loss_cls: 0.2091  loss_box_reg: 0.1249  time: 0.7708  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:17:58 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 1419  total_loss: 0.3632  loss_cls: 0.2263  loss_box_reg: 0.1376  time: 0.7705  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:18:14 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 1439  total_loss: 0.371  loss_cls: 0.2138  loss_box_reg: 0.1349  time: 0.7705  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:18:29 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 1459  total_loss: 0.3711  loss_cls: 0.2235  loss_box_reg: 0.1426  time: 0.7707  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:18:45 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 1479  total_loss: 0.3566  loss_cls: 0.2196  loss_box_reg: 0.1336  time: 0.7706  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:19:00 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 1499  total_loss: 0.3534  loss_cls: 0.2283  loss_box_reg: 0.1287  time: 0.7706  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:19:16 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 1519  total_loss: 0.3906  loss_cls: 0.2456  loss_box_reg: 0.1457  time: 0.7705  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:19:31 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 1539  total_loss: 0.3424  loss_cls: 0.2219  loss_box_reg: 0.1304  time: 0.7702  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:19:46 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1559  total_loss: 0.341  loss_cls: 0.2176  loss_box_reg: 0.1235  time: 0.7703  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:20:02 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 1579  total_loss: 0.3408  loss_cls: 0.2119  loss_box_reg: 0.1219  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:20:17 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 1599  total_loss: 0.3779  loss_cls: 0.2347  loss_box_reg: 0.1251  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:20:33 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 1619  total_loss: 0.3539  loss_cls: 0.2114  loss_box_reg: 0.1318  time: 0.7702  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:20:49 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 1639  total_loss: 0.3368  loss_cls: 0.2042  loss_box_reg: 0.1302  time: 0.7703  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:21:04 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 1659  total_loss: 0.3431  loss_cls: 0.2121  loss_box_reg: 0.1325  time: 0.7703  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:21:20 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 1679  total_loss: 0.3369  loss_cls: 0.2089  loss_box_reg: 0.1403  time: 0.7703  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:21:36 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 1699  total_loss: 0.342  loss_cls: 0.2169  loss_box_reg: 0.124  time: 0.7705  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:21:51 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 1719  total_loss: 0.3248  loss_cls: 0.1877  loss_box_reg: 0.1349  time: 0.7704  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:22:06 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 1739  total_loss: 0.3343  loss_cls: 0.1956  loss_box_reg: 0.1333  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:22:22 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 1759  total_loss: 0.3749  loss_cls: 0.2386  loss_box_reg: 0.1274  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:22:37 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 1779  total_loss: 0.3605  loss_cls: 0.2186  loss_box_reg: 0.1396  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:22:53 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 1799  total_loss: 0.3088  loss_cls: 0.1811  loss_box_reg: 0.1225  time: 0.7700  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:23:08 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 1819  total_loss: 0.3174  loss_cls: 0.1895  loss_box_reg: 0.117  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:23:23 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 1839  total_loss: 0.3122  loss_cls: 0.2025  loss_box_reg: 0.1243  time: 0.7699  data_time: 0.0042  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:23:39 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 1859  total_loss: 0.3176  loss_cls: 0.196  loss_box_reg: 0.1092  time: 0.7699  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:23:54 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 1879  total_loss: 0.367  loss_cls: 0.2181  loss_box_reg: 0.132  time: 0.7699  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:24:10 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 1899  total_loss: 0.3301  loss_cls: 0.2026  loss_box_reg: 0.1347  time: 0.7700  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:24:25 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 1919  total_loss: 0.322  loss_cls: 0.1952  loss_box_reg: 0.1284  time: 0.7699  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:24:41 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 1939  total_loss: 0.3526  loss_cls: 0.2181  loss_box_reg: 0.1209  time: 0.7700  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:24:57 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 1959  total_loss: 0.3185  loss_cls: 0.1902  loss_box_reg: 0.1198  time: 0.7700  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:25:12 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 1979  total_loss: 0.3353  loss_cls: 0.2058  loss_box_reg: 0.1274  time: 0.7699  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:25:28 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1999  total_loss: 0.3246  loss_cls: 0.1734  loss_box_reg: 0.1235  time: 0.7699  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:25:43 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 2019  total_loss: 0.3057  loss_cls: 0.1901  loss_box_reg: 0.1254  time: 0.7700  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:25:58 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 2039  total_loss: 0.3024  loss_cls: 0.1851  loss_box_reg: 0.1242  time: 0.7700  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:26:14 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 2059  total_loss: 0.3043  loss_cls: 0.1869  loss_box_reg: 0.1104  time: 0.7701  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:26:30 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 2079  total_loss: 0.3056  loss_cls: 0.1843  loss_box_reg: 0.1118  time: 0.7701  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:26:46 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 2099  total_loss: 0.3228  loss_cls: 0.1985  loss_box_reg: 0.1265  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:27:01 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 2119  total_loss: 0.3066  loss_cls: 0.1903  loss_box_reg: 0.1292  time: 0.7703  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:27:17 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 2139  total_loss: 0.3233  loss_cls: 0.2002  loss_box_reg: 0.1099  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:27:32 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 2159  total_loss: 0.3316  loss_cls: 0.2062  loss_box_reg: 0.1286  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:27:48 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 2179  total_loss: 0.3236  loss_cls: 0.1963  loss_box_reg: 0.1258  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:28:03 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 2199  total_loss: 0.3542  loss_cls: 0.2252  loss_box_reg: 0.1254  time: 0.7702  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:28:19 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 2219  total_loss: 0.357  loss_cls: 0.2104  loss_box_reg: 0.1333  time: 0.7703  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:28:34 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 2239  total_loss: 0.3131  loss_cls: 0.1926  loss_box_reg: 0.1201  time: 0.7703  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:28:50 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 2259  total_loss: 0.2884  loss_cls: 0.1658  loss_box_reg: 0.1217  time: 0.7704  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:29:06 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 2279  total_loss: 0.3219  loss_cls: 0.1845  loss_box_reg: 0.1303  time: 0.7705  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:29:21 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 2299  total_loss: 0.3216  loss_cls: 0.1843  loss_box_reg: 0.1152  time: 0.7704  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:29:37 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 2319  total_loss: 0.312  loss_cls: 0.1857  loss_box_reg: 0.1319  time: 0.7703  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:29:52 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 2339  total_loss: 0.2979  loss_cls: 0.1764  loss_box_reg: 0.1154  time: 0.7704  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:30:08 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 2359  total_loss: 0.3221  loss_cls: 0.1904  loss_box_reg: 0.1296  time: 0.7703  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:30:23 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 2379  total_loss: 0.3319  loss_cls: 0.1821  loss_box_reg: 0.1232  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:30:39 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 2399  total_loss: 0.2848  loss_cls: 0.1752  loss_box_reg: 0.1106  time: 0.7703  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:30:54 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 2419  total_loss: 0.3185  loss_cls: 0.1787  loss_box_reg: 0.1363  time: 0.7702  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:31:10 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 2439  total_loss: 0.283  loss_cls: 0.1782  loss_box_reg: 0.1101  time: 0.7702  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:31:26 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2459  total_loss: 0.2981  loss_cls: 0.1789  loss_box_reg: 0.1145  time: 0.7702  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:31:40 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 2479  total_loss: 0.2761  loss_cls: 0.1633  loss_box_reg: 0.1123  time: 0.7701  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:31:56 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 2499  total_loss: 0.2776  loss_cls: 0.1585  loss_box_reg: 0.1195  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:32:12 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2519  total_loss: 0.2821  loss_cls: 0.1691  loss_box_reg: 0.1142  time: 0.7701  data_time: 0.0047  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:32:27 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 2539  total_loss: 0.3018  loss_cls: 0.1778  loss_box_reg: 0.1184  time: 0.7701  data_time: 0.0046  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:32:43 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 2559  total_loss: 0.3071  loss_cls: 0.1765  loss_box_reg: 0.1172  time: 0.7702  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:32:58 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 2579  total_loss: 0.2809  loss_cls: 0.1641  loss_box_reg: 0.1154  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:33:14 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 2599  total_loss: 0.3043  loss_cls: 0.1818  loss_box_reg: 0.1294  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:33:29 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 2619  total_loss: 0.2962  loss_cls: 0.173  loss_box_reg: 0.1148  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:33:45 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2639  total_loss: 0.2767  loss_cls: 0.1597  loss_box_reg: 0.1139  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:34:01 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 2659  total_loss: 0.3026  loss_cls: 0.1914  loss_box_reg: 0.1132  time: 0.7702  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:34:16 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2679  total_loss: 0.2924  loss_cls: 0.1734  loss_box_reg: 0.1156  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:34:32 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 2699  total_loss: 0.2576  loss_cls: 0.1426  loss_box_reg: 0.1103  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:34:47 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 2719  total_loss: 0.2832  loss_cls: 0.1682  loss_box_reg: 0.1132  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:35:02 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 2739  total_loss: 0.3123  loss_cls: 0.1733  loss_box_reg: 0.1218  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:35:18 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 2759  total_loss: 0.269  loss_cls: 0.1633  loss_box_reg: 0.1093  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:35:33 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 2779  total_loss: 0.274  loss_cls: 0.1539  loss_box_reg: 0.1124  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:35:49 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 2799  total_loss: 0.2888  loss_cls: 0.1747  loss_box_reg: 0.108  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:36:04 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 2819  total_loss: 0.277  loss_cls: 0.1565  loss_box_reg: 0.1105  time: 0.7701  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:36:20 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2839  total_loss: 0.2968  loss_cls: 0.1772  loss_box_reg: 0.1173  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:36:36 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2859  total_loss: 0.2878  loss_cls: 0.174  loss_box_reg: 0.1118  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:36:51 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 2879  total_loss: 0.2937  loss_cls: 0.1688  loss_box_reg: 0.1066  time: 0.7700  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:37:07 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2899  total_loss: 0.2661  loss_cls: 0.1486  loss_box_reg: 0.1101  time: 0.7700  data_time: 0.0045  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:37:22 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 2919  total_loss: 0.2627  loss_cls: 0.1497  loss_box_reg: 0.1112  time: 0.7700  data_time: 0.0042  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:37:37 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2939  total_loss: 0.2597  loss_cls: 0.1387  loss_box_reg: 0.113  time: 0.7701  data_time: 0.0043  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:37:53 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 2959  total_loss: 0.2863  loss_cls: 0.1588  loss_box_reg: 0.1084  time: 0.7701  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:38:09 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2979  total_loss: 0.2874  loss_cls: 0.1506  loss_box_reg: 0.1137  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:38:25 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.2818  loss_cls: 0.1624  loss_box_reg: 0.1261  time: 0.7702  data_time: 0.0044  lr: 0.001  max_mem: 3239M\n",
      "\u001b[32m[04/05 22:38:25 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:38:29 (0.7702 s / it)\n",
      "\u001b[32m[04/05 22:38:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:38:47 (0:00:18 on hooks)\n",
      "\u001b[32m[04/05 22:38:25 d2.data.datasets.coco]: \u001b[0mLoaded 382 images in COCO format from ../datasets/Duck-Farm/annotations/labels_val.json\n",
      "\u001b[32m[04/05 22:38:25 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    duck    | 724          |  slapped   | 2            |    dead    | 25           |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 751          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/05 22:38:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 22:38:25 d2.data.common]: \u001b[0mSerializing 382 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 22:38:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.20 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/05 22:38:25 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "# config 파일을 토대로 trainer를 불러옵니다.\n",
    "trainer = DefaultTrainer(cfg)\n",
    "# 가장 최근의 checkpoint를 불러오거나(resume=True인 경우) config 파일의 weights 링크로부터 weights를 불러옵니다.\n",
    "trainer.resume_or_load(cfg)\n",
    "# 학습을 진행합니다.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0001999.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 01:49:46 d2.data.datasets.coco]: \u001b[0mLoaded 382 images in COCO format from ../datasets/Duck-Farm/annotations/labels_val.json\n",
      "\u001b[32m[04/05 01:49:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 01:49:46 d2.data.common]: \u001b[0mSerializing 382 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 01:49:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.20 MiB\n",
      "\u001b[32m[04/05 01:49:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 382 batches\n",
      "\u001b[32m[04/05 01:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/382. Dataloading: 0.0005 s/iter. Inference: 0.0763 s/iter. Eval: 0.0001 s/iter. Total: 0.0770 s/iter. ETA=0:00:28\n",
      "\u001b[32m[04/05 01:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 77/382. Dataloading: 0.0009 s/iter. Inference: 0.0750 s/iter. Eval: 0.0001 s/iter. Total: 0.0761 s/iter. ETA=0:00:23\n",
      "\u001b[32m[04/05 01:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 143/382. Dataloading: 0.0009 s/iter. Inference: 0.0750 s/iter. Eval: 0.0001 s/iter. Total: 0.0761 s/iter. ETA=0:00:18\n",
      "\u001b[32m[04/05 01:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 207/382. Dataloading: 0.0009 s/iter. Inference: 0.0759 s/iter. Eval: 0.0001 s/iter. Total: 0.0770 s/iter. ETA=0:00:13\n",
      "\u001b[32m[04/05 01:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 270/382. Dataloading: 0.0009 s/iter. Inference: 0.0765 s/iter. Eval: 0.0001 s/iter. Total: 0.0776 s/iter. ETA=0:00:08\n",
      "\u001b[32m[04/05 01:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 335/382. Dataloading: 0.0009 s/iter. Inference: 0.0765 s/iter. Eval: 0.0001 s/iter. Total: 0.0776 s/iter. ETA=0:00:03\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.370947 (0.077907 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:28 (0.076625 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.579\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.622\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.794\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.797\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 49.163 | 64.219 | 57.906 | 0.000 | 20.678 | 49.234 |\n",
      "\u001b[32m[04/05 01:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
      "| duck       | 61.687 | slapped    | 8.058 | dead       | 77.744 |\n",
      "OrderedDict([('bbox', {'AP': 49.16299516617133, 'AP50': 64.21888284193523, 'AP75': 57.90641864263948, 'APs': 0.0, 'APm': 20.678160919540232, 'APl': 49.233889236072656, 'AP-duck': 61.68665832882594, 'AP-slapped': 8.05830583058306, 'AP-dead': 77.74402133910499})])\n"
     ]
    }
   ],
   "source": [
    "# 799\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"Duck-Farm-val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"Duck-Farm-val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
